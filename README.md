# Ads-Click-Though_Rate-Optimization

The Multi Armed Bandit Problem can be solved by using Reinforcement Learning. 


There are two approaches that can be used to solve the Multi Armed Bandit Problem:
1. Upper Bound Confidence, Reinforcement Learning
2. Thompson Sampling, Reinforcement Learning


Observations and researchs have shown that Thompson Sampling gives more accurate results in less number of iterations as compared to Upper Bound Confidence (Paper reference: https://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling.pdf). 
Hence I have solved Ads-CTR-Optimization using Thompson Sampling.


What is Multi Bandit Problem: https://www.optimizely.com/optimization-glossary/multi-armed-bandit/ / https://web.stanford.edu/class/cs229t/2017/Lectures/bandits.pdf

What is Reinforcement Learning:https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf

What is Upper Confidence Bound(UCB): https://www.geeksforgeeks.org/upper-confidence-bound-algorithm-in-reinforcement-learning/

What is Thompson Sampling(TS): https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf

Dataset used: https://www.kaggle.com/akram24/ads-ctr-optimisation
